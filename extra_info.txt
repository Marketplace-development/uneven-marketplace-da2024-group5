During the development of our platform, we made several deliberate choices to focus on simplicity and ensure a streamlined user experience.

    We decided not to differentiate between providers and customers. Creating separate interfaces for these roles would have added complexity without offering significant value, as users on our platform can seamlessly act as both providers and customers. 
    --> To keep the design efficient, we implemented a single User class that supports all functionalities.

    Trust and safety features, such as ID verification, badges, or in-app reporting, were not included in this version as they were outside the primary scope of our project. 
    --> Instead, we focused on building a secure and functional platform and for account safety, we implemented secure login with password authentication.

    While we considered generating revenue through comissions or advertisements (using algorithms to offer location-based ads for services like local guides or restaurants). 
    --> However These features were too complicated to implement, so we decided to spend our time making sure the main functions of our platform work well. 
    --> Thus we excluded these options for revenue streams and focused on improving the basics, but we did include these concept in our visual ontology and ERD as a foundation for future development.

    We considered adding a comparison feature to let users view two listings side by side, but we decided not to include it as we felt it didn’t add much value to the platform.

    We did not create a direct messaging system between users, but we did include the concept in our visual ontology and ERD as a foundation for future development.
    --> Instead, users can access the seller's email address after making a purchase and communicate with them directly via email.

Use of Algorithms:

    We developed an algorithm that tailors recommendations based on user preferences gathered from a short questionnaire. This personalization improves the user experience by suggesting listings that align with individual interests.
    This algorithm is crucial for helping users discover listings that are most relevant to their interests, thereby improving engagement and satisfaction.

    Our algorithm is based on 3 pillars: gathering user preferences, storing these preferences and displaying the personalized suggestions.
    
    1 Gathering user preferences: At the time of registration, we prompt users to participate in what we have called the "Travel Preferences" section.
    This section consists of a variety of travel-related pictures followed by a questionnaire.
    
    Each listing on our platform is categorized under one of the following tags: "Family," "Nature," "Culture," "Romantic," "Adventure," "City Trips," "Sport & Active," "Festivals & Events," "Budget & Backpacking," "Wellness & Relaxation," or "Roadtrip & Multi-Destination." 
    These tags are essential for aligning users with itineraries that best match their preferences.
    Upon registration, a user's preferences for these categories are initially set to zero. 
    We employ a JSONB data type within our database to efficiently monitor and update these preferences based on user interactions. This approach ensures that the travel listings displayed to each user are personalized, enhancing their likelihood of finding appealing experiences.


    So our first way to update the user preferences is with the question "Which photos are you most drawn to? (multiple answers possible)". the answer options are 10 photos (ranging from a mountain landscape to a breathtaking spa).
    All these options have a checkbox (square), because a checkbox allows multiple answers to be selected. 
    All these photos are linked to 1 or more categories (for example, the mountain scenery is linked to the categories: “Adventure”, “Nature”, “Sport & Active”, “Budget & Backpacking” and “Roadtrip & Multi-Destination”, while the picture of Tomorrowland is only linked to the category "Festivals & Events").
    After these photo-related question, there are 5 more questions to gauge people's interests. Some of these questions (1,2 and 4) make use of radiobuttons (circles) what prevents people to select multiple answers and the other questions (3 and 5) make use of checkboxes.
    As with the pictures, each answer option for each question is always linked to 1 or more categories. 
    When you are ready to register and press the green button "Register" at the bottom of the page, all categories linked to the selected photos and other choices will be increased by 1.
    this way a user has specific preferences even before he likes or buys listings and we can already give him suggestions (on the ViaVia page, our homescreen)
    
    We all know that buying behavior and interests can change and to support this we have made the process agile.
    Every time a user likes a listing, the value of the category linked to this listing will be increased by 1, and when a listing gets unliked, the value will be reduced by 1.
    We believe that buying a listing should be more decisive than liking it and for this reason the value is increased by 2 on a purchase.

    2 Storing the preferences: These preferences are stored as a JSON object in our database under each user's profile. 
    This JSON object contains key-value pairs where the keys represent the travel categories and the values denote the strength of interest in that category, based on actions already explained (1 Gathering user preferences).

    3 Displaying the personalized suggestions:
    The algorithm first retrieves the preference scores for each category from the user's profile.
    Based on these scores, the algorithm identifies the top categories. This involves sorting the categories by their preference scores in descending order.
    If only one category has the highest score, the algorithm then finds the second highest score and includes categories with this score as well.

    Short explanation of which categories will be displayed:
    Only the categories with the highest and the second-highest scores are included if there's a single winner.
    Case 1: If the highest score is shared by multiple categories, all categories with this score are displayed, ignoring the second-highest score.
    Case 2: If there's a clear highest score but a tie at the second place, both the highest score category and all categories tied for the second place are displayed.

    Fetching and Displaying Listings: For each selected category, listings associated with these categories are fetched from the database.
    Listings are displayed on the homepage, categorized or tagged according to the determined preferences. This personalized display helps users quickly find listings that are likely to be of interest, enhancing the user experience

    Future Directions: To further refine our recommendations, we plan to integrate advanced predictive analytics, considering user behavior patterns over time. 
    This will let us proactively adjust preferences even before explicit actions are made by the user (besides liking and buying travel guides).

    In the future, additional algorithms could be integrated to enhance functionality. 
    --> For example, during user registration, we could collect location data (using the external GeoNames API, see additional info below) to power features like targeted recommendations, advertisements for local businesses or even location-based listing filters (such as radius filtering, travel time filters, ...)
    --> But for now, our focus remains on delivering a functional recommendation system while leaving room for these enhancements in subsequent phases.

To power/develop our platform and deliver a seamless user experience/smooth operation of our platform, we rely on a combination of tools and technologies, including:
    
    The use of the MVC as our architectural pattern to separate application functionality and promote organized programming
        --> Model: Defines the structure of the data and is connected to our database
        --> View (templates): Handles the user interface and data presentation (Consists of HTML for text and CSS for the styling)
        --> Controller (routes): Updates the model and view based on user input

    The use of Flask: Flask serves as the core of our platform, offering a lightweight yet powerful framework for building the website. 
    It manages routing, server-side logic, and the integration of various components, ensuring everything runs smoothly and efficiently.
        --> Flask automatically separates certain components and is flexible enough to maintain a clear and organized structure.  
        --> We chose Flask because it’s a straightforward framework for developing MVC (Model-View-Controller) software and works seamlessly with Python, making it a logical choice for our project. 

    The use of Flask-SQLAlchemy: Flask-SQLAlchemy is the bridge between our Python code and the database. 
        --> SQLAlchemy converts our Python code into SQL statements for the database. When the database returns data, SQLAlchemy translates it back into Python code.
        --> Thanks to this ORM (Object-Relational Mapping), we don’t need to write SQL statements directly in our Flask model files.

    The use of flash en flash errors: In our project, Flash messages are used to provide users with instant feedback about their actions, such as successful form submissions, account updates, or errors during interactions. 
        --> They help enhance the user experience by delivering clear and concise notifications directly on the interface.
        --> Flash Errors are specifically employed to alert users about issues, such as invalid input, failed authentication, or incomplete forms. 
        --> This ensures users understand what went wrong and can take corrective action. 
        --> Together, these tools improve communication and interactivity, making the platform more intuitive and user-friendly.

    The use of Jinja and Flask-Snippets extensions: Extensions in VS Code add extra functionality to us (the editors / programmers). In this case, Jinja and Flask-Snippets specifically assist in developing web applications with Flask and Jinja2. 
        They provide:
            - Syntax Highlighting: This makes the code more readable.
            - Code Autocompletion: Offers suggestions as you type, allowing for faster and more accurate development.

    The use of requests: The requests library enables seamless communication with external APIs, such as fetching live data like weather updates, currency exchange rates, or travel insights. 
        --> This enriches the platform with dynamic, real-time content. This Python library enables the platform to send HTTP requests to external APIs (like Geonames --> see further)

    The use of Blueprint: We used Flask's Blueprint to break our application into smaller, modular components. 
        --> This allowed us to organize our routes and functionality into separate files, making our code easier to maintain and scale
    
    The use of jsonify: We used jsonify to turn our data (like lists or information about users) into a format that can easily be sent back and forth between the server and the website. 
        --> The jsonify module was used to easily convert Python data structures (like dictionaries or lists) into JSON format, which is the standard format for API responses
        --> This was essential for sending data between the server and the client in a structured and readable way, allowing us to handle things like displaying user information, listings, and handling requests from the frontend in a seamless manner.
        --> Thus, this is important because the server and website need to communicate, and jsonify makes sure the data is sent in a way that both sides can understand and display properly.

    The use of the re module: We used the re (regular expressions) module to make our development process easier and more efficient while building the platform. 
        --> By leveraging regular expressions, we were able to simplify tasks that involve searching, validating, and manipulating strings of text.
        --> For example, we used it to validate user inputs, such as ensuring email addresses follow the correct format.

    The use of psycopg2-binary: Psycopg2-binary is the key to our connection with the PostgreSQL database on supabase. 
        --> It ensures secure, reliable, and efficient storage and retrieval of essential platform data, forming the backbone of data-driven features.

    The use of supabase for the database of our website (also see marketplace_ideation.txt file):
        --> We use a database in our website to efficiently store and manage structured data, such as user information, itineraries, transactions... This ensures our data is organized, easily accessible, and secure. 
        --> A database is crucial for providing dynamic content and scaling as our user base grows.
        --> We chose Supabase because it offers a powerful and developer-friendly backend solution built on PostgreSQL. 
        --> Its open-source nature and ease of integration made it the perfect choice for our needs, allowing us to focus on building the core functionality of our platform without worrying about complex backend setups.

    The use of buckets in our database on supabase: Supabase buckets provide a secure and scalable solution for storing and managing files like PDFs or pictures for each itinerary on our platform. 
        --> Each PDF and picture is uploaded to a designated bucket and linked to a specific listing in the database, with the file’s URL securely stored and hidden until a successful purchase is made. 
        --> We wanted to implement an automatic solution to ensure uploaded images are rectangular, but this proved too complex and not core to our project. For our example itineraries, we manually adjusted images to maintain the layout. 
        Currently, users can still upload images of various formats, which can disrupt the design, but in the future, we aim to restrict this to preserve visual consistency.
        --> Buyers can only access their purchased files through a "Download" button, enabled after transaction verification. Supabase policies and backend validation ensure strict access control, allowing only authenticated and eligible users to retrieve the files. 
        This setup ensures seamless integration, robust security, and a user-friendly experience for both sellers and buyers.

    The use of Bootstrap: Bootstrap ensures the platform looks great on all devices with its responsive, modern design components. 
        --> From buttons to layouts, it provides a polished user interface that enhances navigation and usability.

    The use of the external GeoNames API: We integrated GeoNames into our platform to enhance location-based features by providing accurate, real-time geographic data. This includes offering location suggestions through an auto-completion feature, which helps users enter valid places easily and without typos.
        --> By leveraging GeoNames, we can validate that locations follow the correct format and actually exist, ensuring data integrity. 
        --> however: Since we are working with a free API, GeoNames imposes a limitation of 1,000 requests per hour. This means that every time a user types more than three letters, a request is sent to the GeoNames API to retrieve location suggestions. 
            Thus, with this limitation, we need to be mindful of how often requests are made to avoid exceeding the cap, especially during periods of high user activity. 
    
    The use of chatGPT: We used ChatGPT to assist with the overall programming of our platform, serving as a valuable resource throughout the development process. 
        --> ChatGPT helped us troubleshoot errors, provided coding solutions, and guided us on how to implement features we envisioned but weren’t sure how to execute.  --> Whether it was debugging complex issues, offering suggestions for optimizing the platform, or explaining how to integrate various technologies, ChatGPT played a key role in enhancing the development workflow. Its ability to generate code snippets, offer explanations, and suggest best practices allowed us to move forward with confidence and streamline the creation of a functional and efficient platform.

    We chose not to use Flask-Migrate during the development of our platform due to concerns about the potential risks associated with unintended mistakes that could negatively impact our database. 
        --> Flask-Migrate is a powerful tool for handling database migrations, but it also comes with the possibility of making errors, especially when applying changes or rolling back migrations. 
        --> In a development environment where constant changes were being made to the database schema, we wanted to avoid scenarios where an accidental migration could delete or corrupt important data, or cause other issues that could halt our progress. 
            So, instead, we opted for a more manual approach to database management to maintain greater control over the changes we made, minimizing the chance of any serious setbacks. 
            By doing so, we could carefully test each change and ensure the stability and integrity of our data throughout the development process.